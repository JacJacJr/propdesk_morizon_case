
# Morizon Crawler and Scraper Application

## Overview

This application consists of two main Python scripts: `morizon_crawler_html.py` and `morizon_scrapper_html.py`. These scripts work together to crawl and scrape real estate listings from the Morizon website.

## Requirements

To run the application, ensure you have the following installed:

- Python >=3.10
- Selenium
- BeautifulSoup
- pandas
- Firefox WebDriver (geckodriver)
- CSV and JSON libraries

Additional dependencies may be listed in the `requirements.txt` file.

## Application Logic

### morizon_crawler_html.py

This script is responsible for crawling the Morizon website to collect links to individual property listings. It performs the following steps:

1. **Determine the Number of Pages**: The script can prompt the user to enter the maximum number of pages to scrape. If the user enters 0, it automatically determines the total number of pages available on the platform.

2. **Fetch Links**: Iterates through each page, extracts property listing links using regular expressions, ensures uniqueness of each link by tracking IDs, and collects all valid URLs.

3. **Save Links**: Saves all collected links into a CSV file with a timestamped filename for later use by the scraper script.

### morizon_scrapper_html.py

This script takes the collected links from the crawler and scrapes detailed information from each property listing. Its workflow includes:

1. **Read Links**: Loads the list of property URLs from the CSV file generated by the crawler.

2. **Scrape Details**: For each URL, it fetches the page content using Selenium, extracts relevant details such as price, property type, location, and other attributes using BeautifulSoup and regular expressions.

3. **Handle Errors**: Implements error handling for various exceptions like missing elements, timeouts, and WebDriver issues, and logs errors accordingly.

4. **Save Data**: Stores the scraped data into JSON and CSV files for further analysis or usage.

## Previous Approach

Initially, the application used a JavaScript-based approach to query and interact with HTML elements on the Morizon platform. However, due to recent changes that involved encoding the names of HTML objects, this method became unreliable. Consequently, the application was refactored to parse and extract data directly from the raw HTML content of the pages.




